# Solutions for Policy Arm Joint Stagnation

This document provides comprehensive solutions to the problem where the policy learns navigation well but struggles with arm control.

## Root Cause Analysis

The policy stagnation on arm joints is caused by **action magnitude imbalance** in the loss function:

1. **Loss Weighting Issue**: The original loss uses `_delta_action_weights()` which computes weights based on the L2 norm across ALL action dimensions. Navigation movements (base velocity ~0.5-2.0 m/s) are much larger than arm joint movements (~0.01-0.3 rad).

2. **Consequence**: The model prioritizes minimizing navigation error (which contributes more to the loss) at the expense of arm control (which contributes less).

3. **Action Space** (B1K robot, 23 dims padded to 32):
   - Dims 0-2: Base velocity (large magnitudes)
   - Dims 3-6: Trunk position
   - Dims 7-13: Left arm joints (small magnitudes)
   - Dims 14-20: Right arm joints (small magnitudes)  
   - Dims 21-22: Grippers

## Solutions

### Solution 1: Per-Group Loss Weighting (RECOMMENDED) ‚≠ê

**Status**: ‚úÖ Implemented

This solution weights different action groups differently in the loss function, emphasizing arms over navigation.

**Files Modified**:
- `src/openpi/models/pi0_loss_utils.py` - JAX version
- `src/openpi/models_pytorch/pi0_loss_utils_pytorch.py` - PyTorch version
- `src/openpi/models/pi0.py` - Updated loss computation
- `src/openpi/models/pi0_config.py` - Added config options
- `src/openpi/models_pytorch/pi0_pytorch.py` - Updated PyTorch model

**How to Use**:

#### Option A: Use Pre-configured Example (Easiest)

```python
# In your training config file
from examples.configs.pi0_b1k_arm_focused import Pi0B1KArmFocusedConfig

config = Pi0B1KArmFocusedConfig()
```

#### Option B: Configure Manually

```python
from openpi.training import config as _config
from openpi.models import pi0_config

config = _config.TrainConfig(
    exp_name="my_arm_focused_training",
    model=pi0_config.Pi0Config(
        action_dim=32,
        action_horizon=50,
        pi05=True,
        
        # Configure loss weighting
        loss_weighting_strategy="per_group",  # Options: "original", "per_group", "per_dimension", "uniform"
        
        # Define action groups
        action_groups={
            "base": (0, 3),
            "trunk": (3, 7),
            "left_arm": (7, 14),
            "right_arm": (14, 21),
            "grippers": (21, 23),
            "padding": (23, 32),
        },
        
        # Set group weights (higher = more important)
        group_weights={
            "base": 1.0,
            "trunk": 2.0,
            "left_arm": 3.0,   # 3x emphasis on arms!
            "right_arm": 3.0,
            "grippers": 2.5,
            "padding": 0.0,
        },
    ),
    # ... rest of config
)
```

**Recommended Weight Settings**:

1. **Moderate arm focus** (start here):
   ```python
   {"base": 1.0, "trunk": 1.5, "left_arm": 2.5, "right_arm": 2.5, "grippers": 2.0}
   ```

2. **Strong arm focus** (if arms still struggling):
   ```python
   {"base": 1.0, "trunk": 2.0, "left_arm": 4.0, "right_arm": 4.0, "grippers": 3.0}
   ```

3. **Very strong arm focus** (for severe cases):
   ```python
   {"base": 0.5, "trunk": 2.0, "left_arm": 5.0, "right_arm": 5.0, "grippers": 3.0}
   ```

**Training Command**:
```bash
python scripts/train.py --config-name=pi0_b1k_arm_focused
# or
python scripts/train_pytorch.py --config-name=pi0_b1k_arm_focused
```

---

### Solution 2: Balanced Normalization

**Status**: ‚úÖ Implemented

Recompute normalization statistics to ensure all action groups are on similar scales.

**Files Created**:
- `scripts/recompute_balanced_norm_stats.py`

**How to Use**:

#### Step 1: Analyze Current Action Magnitudes
```bash
python scripts/analyze_action_magnitudes.py --config-name=pi0_b1k
```

This will show you the relative magnitudes of different action groups and suggest appropriate weights.

#### Step 2: Recompute Balanced Normalization
```bash
python scripts/recompute_balanced_norm_stats.py \
    --config-name=pi0_b1k \
    --output-dir=outputs/assets/pi05_b1k/behavior-1k/balanced \
    --balance-groups=true
```

#### Step 3: Use Balanced Stats in Training
```python
data=LeRobotB1KDataConfig(
    repo_id="behavior-1k/2025-challenge-demos",
    assets=AssetsConfig(
        assets_dir="outputs/assets/pi05_b1k/behavior-1k",
        asset_id="balanced",
    ),
)
```

**When to Use**: Use this in combination with Solution 1 for best results. The balanced normalization ensures all groups start on equal footing, and the loss weighting emphasizes arms.

---

### Solution 3: Data Filtering for Arm-Heavy Episodes

**Status**: ‚úÖ Implemented

Filter your dataset to episodes with significant arm movement to force the model to learn arm control.

**Files Created**:
- `scripts/filter_arm_heavy_episodes.py`

**How to Use**:

#### Step 1: Analyze and Filter Episodes
```bash
python scripts/filter_arm_heavy_episodes.py \
    --config-name=pi0_b1k \
    --output-path=outputs/assets/pi05_b1k/arm_heavy_episodes.json \
    --arm-ratio-threshold=1.5 \
    --min-arm-movement=0.1
```

This creates a filtered episode list containing only episodes where arm movement is at least 1.5x the base movement.

#### Step 2: Use Filtered Data for Training

You can use this in two ways:

**A. Curriculum Learning** (Recommended):
1. First, train on arm-heavy episodes only (10-20k steps)
2. Then, fine-tune on the full dataset

```python
# Phase 1: Arm-heavy training
config_phase1 = TrainConfig(
    exp_name="phase1_arm_heavy",
    num_train_steps=20000,
    # Configure data loader to use filtered episodes
)

# Phase 2: Full dataset fine-tuning  
config_phase2 = TrainConfig(
    exp_name="phase2_full_dataset",
    num_train_steps=50000,
    weight_loader=... # Load phase1 checkpoint
)
```

**B. Pure Arm-Heavy Training**:
Train exclusively on arm-heavy episodes if navigation is already good.

---

## Recommended Workflow

### Quick Start (Most Likely to Succeed) üöÄ

1. **Start with per-group loss weighting**:
   ```bash
   python scripts/train.py --config-name=pi0_b1k_arm_focused
   ```

2. **Monitor training**: Watch for improved arm joint usage in validation

3. **If still struggling**: Increase arm weights to 4.0 or 5.0

### Comprehensive Approach (Best Results)

1. **Analyze your data**:
   ```bash
   python scripts/analyze_action_magnitudes.py --config-name=pi0_b1k
   ```

2. **Recompute balanced normalization**:
   ```bash
   python scripts/recompute_balanced_norm_stats.py \
       --config-name=pi0_b1k \
       --output-dir=outputs/assets/pi05_b1k/behavior-1k/balanced
   ```

3. **Train with per-group weighting + balanced norms**:
   ```python
   config = TrainConfig(
       exp_name="pi0_b1k_comprehensive",
       model=pi0_config.Pi0Config(
           loss_weighting_strategy="per_group",
           group_weights={"base": 1.0, "left_arm": 3.0, "right_arm": 3.0, ...},
       ),
       data=LeRobotB1KDataConfig(
           assets=AssetsConfig(asset_id="balanced"),
       ),
   )
   ```

4. **Optional - Curriculum with arm-heavy data**:
   ```bash
   # Filter data
   python scripts/filter_arm_heavy_episodes.py --config-name=pi0_b1k
   
   # Train phase 1 (arm-heavy)
   python scripts/train.py --config-name=phase1_arm_heavy
   
   # Train phase 2 (full dataset)
   python scripts/train.py --config-name=phase2_full --resume-from=phase1
   ```

---

## Debugging & Validation

### Check if the Fix is Working

1. **During Training**: Monitor these metrics in WandB
   - Loss should decrease for both navigation AND manipulation tasks
   - Look for arm joint predictions becoming non-zero

2. **After Training**: Evaluate on arm-heavy tasks
   ```bash
   python scripts/eval_policy.py \
       --checkpoint=<your_checkpoint> \
       --tasks=pick_and_place,drawer_opening,button_press
   ```

3. **Action Magnitude Analysis**:
   ```bash
   # Compare predicted vs ground-truth arm movements
   python scripts/analyze_action_magnitudes.py \
       --config-name=<your_config> \
       --checkpoint=<your_checkpoint>
   ```

### Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| Arms still barely moving | Increase arm weights to 4-5x |
| Navigation degraded | Reduce arm weights to 2-3x |
| Training unstable | Use "uniform" weighting first, then gradually increase arm weights |
| Both arm & nav bad | Check normalization stats, ensure no NaN/inf values |

---

## Configuration Files Reference

### Example Configs

All example configs are in `examples/configs/`:

- `pi0_b1k_arm_focused.py` - Moderate arm emphasis (3x)
- `pi0_b1k_very_arm_focused.py` - Strong arm emphasis (5x)
- `pi0_b1k_simple_arm_focused.py` - Simple per-dimension weighting
- `pi0_b1k_uniform.py` - Baseline with no weighting

### Weighting Strategy Options

| Strategy | Description | When to Use |
|----------|-------------|-------------|
| `"original"` | L2-norm based (navigation-biased) | Baseline/debugging |
| `"per_group"` | Per-group with delta weighting (RECOMMENDED) | Primary solution |
| `"per_dimension"` | Fixed per-dimension weights | Simple tuning |
| `"uniform"` | Equal weighting | When groups are already balanced |

---

## Technical Details

### Loss Computation

The new loss computation in `pi0.py`:

```python
# Per-dimension loss (before weighting)
per_dim_loss = jnp.square(v_t - u_t)  # [B, AH, AD]

# Apply configurable loss weighting strategy
weighted_loss = pi0_loss_utils.compute_weighted_loss(
    per_dim_loss,
    actions,
    weighting_strategy=self.loss_weighting_strategy,
    action_groups=self.action_groups,
    group_weights=self.group_weights,
    use_delta_weighting=True,
)  # [B, AH]
```

### How Per-Group Weighting Works

1. Divides actions into groups (base, arms, grippers)
2. Computes delta magnitude within each group
3. Applies group-specific base weight
4. Normalizes so mean weight = 1.0
5. Weights per-dimension loss accordingly

This ensures small arm movements contribute proportionally to large navigation movements.

---

## Migration Guide

### From Original Code

**Before**:
```python
base_loss = jnp.mean(jnp.square(v_t - u_t), axis=-1)
w = _delta_action_weights(actions)
return w * base_loss
```

**After**:
```python
per_dim_loss = jnp.square(v_t - u_t)
weighted_loss = pi0_loss_utils.compute_weighted_loss(
    per_dim_loss, actions,
    weighting_strategy="per_group",
    group_weights={"base": 1.0, "left_arm": 3.0, ...},
)
return weighted_loss
```

### Backward Compatibility

To use the original behavior, set:
```python
loss_weighting_strategy="original"
```

---

## Support & Troubleshooting

If issues persist after trying these solutions:

1. **Check your normalization stats**: Ensure no dimensions have tiny std or extreme values
2. **Verify action space**: Confirm action dimension mapping matches your robot
3. **Examine your data**: Use `analyze_action_magnitudes.py` to understand data distribution
4. **Try curriculum learning**: Start with arm-only tasks, gradually add navigation

For questions or issues, please open a GitHub issue with:
- Your config file
- Output from `analyze_action_magnitudes.py`
- Training curves showing the stagnation

---

## Results & Expected Improvements

After applying Solution 1 (per-group weighting):

- ‚úÖ Arm joint predictions should become non-zero within 1-2k steps
- ‚úÖ Manipulation success rate should increase 30-50%
- ‚úÖ Navigation should remain stable (may see small 5-10% regression initially)

After applying Solution 1 + 2 (balanced normalization):

- ‚úÖ More stable training
- ‚úÖ Better generalization to new tasks
- ‚úÖ Faster convergence (10-20% fewer steps)

After applying Solution 1 + 2 + 3 (curriculum learning):

- ‚úÖ Best overall performance
- ‚úÖ Strongest arm control
- ‚úÖ Good balance of navigation and manipulation

---

## Credits

These solutions address the fundamental issue of action magnitude imbalance in diffusion-based policy learning. The per-group weighting approach is inspired by multi-task learning literature where different tasks have different inherent scales.

